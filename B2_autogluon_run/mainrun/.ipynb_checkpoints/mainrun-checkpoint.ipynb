{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc2af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cbbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb4cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whorunsit = 'LiezelCluster'  # 'LiezelMac' | 'LiezelCluster'\n",
    "\n",
    "if whorunsit == 'LiezelMac':\n",
    "    home_dir = '/Users/ltamon'\n",
    "elif whorunsit == 'LiezelCluster':\n",
    "    home_dir = '/project/sahakyanlab/ltamon'\n",
    "else:\n",
    "    print(\"The supplied <whorunsit> option is not created in the script.\")\n",
    "\n",
    "wk_dir = home_dir + '/SahakyanLab/GenomicContactDynamics/26_PredictingCp'\n",
    "#csv_dir = wk_dir + '/z_ignore_git/out_makeTable'\n",
    "csv_dir = wk_dir + '/out_makeTable'\n",
    "out_dir = wk_dir + '/out_autogluon_run'\n",
    "#out_dir = wk_dir + '/out_autogluon_run_cpu_medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a002086",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_train_data_subsample = False\n",
    "do_subsample = True # Also set to true to load subsampled data for fit_model = True\n",
    "fit_model = False\n",
    "assess_model = True\n",
    "pred_model = False\n",
    "num_train_points = 1237618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c4e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = 3 # 10G per cpu/gpu\n",
    "num_gpus = 0\n",
    "\n",
    "presets = 'best_quality' #'medium_quality'\n",
    "num_folds_parallel = 2 #3\n",
    "\n",
    "time_limit = 5*60*60 # seconds\n",
    "\n",
    "ag_args_fit = {'num_cpus': num_cpus, 'num_gpus': num_gpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94bc5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcb = 'min2Mb'\n",
    "chrs = ['chr1']\n",
    "chrs_test = ['chr18']\n",
    "feat_regex = 'grp.compl.|grp.kmer3.|grp.kmer1.|grp.GC.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3769abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_id = '5percExceptgrthn18' #'0point1percExceptgrthn18' #'5percExceptgrthn18'\n",
    "percs = np.repeat([5,100], [18,3]) #np.repeat([0.001,0.001], [18,3]) #np.repeat([5,100], [18,3])\n",
    "groups = list(range(1,22))\n",
    "seed_val = 234\n",
    "#[len(percs), len(groups)]\n",
    "#[percs, groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e754b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'LABEL'\n",
    "metric = 'root_mean_squared_error'\n",
    "problem_type = 'regression' # (options: ‘binary’, ‘multiclass’, ‘regression’, ‘quantile’)\n",
    "label_count_threshold = 2 # For multi-class classification problems, this is the minimum number of times a label must appear in dataset in order to be considered an output class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861bdd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chr23 -> chrX in chrs.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chrs[chrs.index('chr23')] = 'chrX'\n",
    "except ValueError:\n",
    "        print(\"No chr23 -> chrX in chrs.\")\n",
    "chrs_id = ''.join(chrs)\n",
    "        \n",
    "feat_regex_id = re.compile('[^a-zA-Z0-9]').sub('', feat_regex)\n",
    "#[chrs_id, feat_regex_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d701654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chr23 -> chrX in chrs_test.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chrs_test[chrs_test.index('chr23')] = 'chrX'\n",
    "except ValueError:\n",
    "        print(\"No chr23 -> chrX in chrs_test.\")\n",
    "chrs_test_id = ''.join(chrs_test)\n",
    "#[chrs_test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e1aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_chrcsv(csv_dir, gcb, chrs):\n",
    "    \n",
    "    df = []\n",
    "    [df.append(pd.read_csv( csv_dir + '/' + gcb + '_' + chr + '_MLtbl.csv' )) for chr in chrs]\n",
    "    df = pd.concat(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def choose_features(df, feat_regex, label_col):\n",
    "    \n",
    "    final_regex = feat_regex + '|' + label_col\n",
    "    is_chosen = [ bool(re.search(pattern=final_regex, string=feat)) for feat in df.columns ] \n",
    "    is_todrop = [not bool for bool in is_chosen]\n",
    "    df.drop(columns=list(df.columns[is_todrop]), inplace=True)\n",
    "\n",
    "    return(df)\n",
    "    \n",
    "def switch_contact(df):\n",
    "    \n",
    "    features = np.array(df.columns)\n",
    "    is_icol = ['.i_' in feat for feat in features]\n",
    "    is_jcol = ['.j_' in feat for feat in features]\n",
    "    \n",
    "    features_switch = np.array(features)\n",
    "    features_switch[is_icol] = features[is_jcol]\n",
    "    features_switch[is_jcol] = features[is_icol]\n",
    "    \n",
    "    df_switch = df.set_axis(features_switch, axis=1, inplace=False)\n",
    "    df_switch = df_switch[features]\n",
    "    df = pd.concat([df, df_switch])\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def sampleGroupInSeries(dfSeries, perc, group, seed_val):\n",
    "    \n",
    "    row_ind_group = dfSeries.index\n",
    "    row_ind_group = row_ind_group[ dfSeries == group ]\n",
    "    \n",
    "    np.random.seed(seed_val)\n",
    "    samp_size = math.ceil( sum(dfSeries == group) * perc / 100 )\n",
    "    row_ind_group_sampled = list( np.random.choice(a = row_ind_group, size=samp_size, replace=False) )\n",
    "    \n",
    "    return(row_ind_group_sampled)\n",
    "\n",
    "def sampleManyGroupsInSeries(dfSeries, percs, groups, seed_val):\n",
    "    \n",
    "    num_groups = len(groups)\n",
    "    seed_generated = np.random.randint(low=0, high=1000, size=num_groups, dtype=int)\n",
    "    \n",
    "    row_ind_manygroups_sampled = []\n",
    "    \n",
    "    for i in range(num_groups):\n",
    "        \n",
    "        perc = percs[i]\n",
    "        group = groups[i]\n",
    "        seed_i = seed_generated[i]\n",
    "        row_ind_manygroups_sampled = row_ind_manygroups_sampled + sampleGroupInSeries(dfSeries, perc, group, seed_val=seed_i)\n",
    "        \n",
    "    return(row_ind_manygroups_sampled)\n",
    "\n",
    "def processData(df, feat_regex, label_col):\n",
    "    \n",
    "    df = choose_features(df, feat_regex, label_col)\n",
    "    print(\"Feature columns chosen.\")\n",
    "    df = switch_contact(df)\n",
    "    print(\"Contacts switched.\")\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "241d4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_id = gcb + '_' + chrs_id + '_MLtbl'\n",
    "if do_subsample:\n",
    "    csv_id = csv_id + '_' + feat_regex_id + '_seed' + str(seed_val) + '_' + sampling_id \n",
    "    \n",
    "csv_path = csv_dir + '/' + csv_id + '.csv'\n",
    "#[csv_id, csv_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "63c279ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data subsample...\n",
      "Subsampling percentages: \n",
      "[  5   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5   5\n",
      " 100 100 100]\n",
      "for each group: \n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
      "Subsampled 15298 training datapoints.\n",
      "Feature columns chosen.\n",
      "Contacts switched.\n",
      "min2Mb_chr22_MLtbl_grpcomplgrpkmer3grpkmer1grpGC_seed234_5percExceptgrthn18: Training data saved as CSV.\n"
     ]
    }
   ],
   "source": [
    "if generate_train_data_subsample:\n",
    "    \n",
    "    print(\"Generating training data subsample...\")\n",
    "    \n",
    "    train_data = concat_chrcsv(csv_dir, gcb, chrs)\n",
    "    \n",
    "    if do_subsample:\n",
    "        ind = sampleManyGroupsInSeries(train_data['LABEL'], percs, groups, seed_val=seed_val)\n",
    "        train_data = train_data.iloc[ind,:]\n",
    "        print('Subsampling percentages: ')\n",
    "        print(percs)\n",
    "        print('for each group: ')\n",
    "        print(groups)\n",
    "        print(\"Subsampled \" + str(len(train_data)) +  \" training datapoints.\")\n",
    "        \n",
    "        train_data = processData(train_data, feat_regex, label_col)\n",
    "        \n",
    "        train_data.to_csv(csv_path)\n",
    "        print(csv_id + \": Training data saved as CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a189bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'agModel_' + gcb + '_' + chrs_id + '_' + feat_regex_id + '_' + presets + '_' + str(time_limit) + 'sec_' + problem_type\n",
    "if do_subsample:\n",
    "    model_id = model_id + '_subsample_seed' + str(seed_val) + '_' + sampling_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab46f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_model:\n",
    "    \n",
    "    print(\"Preparing train data for model fitting...\")\n",
    "    \n",
    "    train_data = TabularDataset(csv_path)\n",
    "    \n",
    "    if do_subsample:\n",
    "        train_data.drop(columns=train_data.columns[0], axis=1, inplace=True)\n",
    "        print(csv_id + \": Loaded subsampled training data from CSV.\")\n",
    "    else: # Make function to avoid repetition of code below\n",
    "        train_data = concat_chrcsv(csv_dir, gcb, chrs)\n",
    "        print(csv_id + \": Loaded full training data from CSV.\")\n",
    "        train_data = processData(train_data, feat_regex, label_col)\n",
    "        \n",
    "    model_id = model_id + '_' + str(len(train_data)) + 'datapoints'\n",
    "\n",
    "model_path = out_dir + '/' + model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adeaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_model:\n",
    "    \n",
    "    print(\"Model fitting...\")\n",
    "    \n",
    "    predictor = TabularPredictor(label=label_col, eval_metric=metric, path=model_path, problem_type=problem_type, learner_kwargs={'label_count_threshold': label_count_threshold}).fit(train_data, ag_args_fit=ag_args_fit, ag_args_ensemble={'num_folds_parallel': num_folds_parallel}, presets=presets, time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae10293",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = out_dir + '/' + model_id + '_' + str(num_train_points) + 'datapoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data from chr used for training\n",
    "if assess_model & do_subsample: # by comparing validation and test score; likely overfitted if score_val > score_test\n",
    "    \n",
    "    print(\"Generating test data...\")\n",
    "    \n",
    "    train_data = concat_chrcsv(csv_dir, gcb, chrs)\n",
    "    train_ind = sampleManyGroupsInSeries(train_data['LABEL'], percs, groups, seed_val=seed_val)\n",
    "    test_ind = sampleManyGroupsInSeries(train_data.drop(index=train_ind, inplace=False)['LABEL'], percs / 2, groups, seed_val=seed_val)\n",
    "    \n",
    "    if np.intersect1d(np.array(train_ind), np.array(test_ind)).any():\n",
    "        raise Exception(\"Overlapping train and test sets.\")\n",
    "    else:\n",
    "        test_data = train_data.iloc[test_ind,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855efc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if assess_model:\n",
    "    \n",
    "    print(\"Assessing model...\")\n",
    "    \n",
    "    predictor = TabularPredictor.load(model_path)\n",
    "    leaderboard = predictor.leaderboard(test_data, silent = True)\n",
    "    leaderboard.to_csv(model_path + '_leaderboard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9302e93",
   "metadata": {},
   "source": [
    "MODEL ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e73e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_model:\n",
    "    test_data = concat_chrcsv(csv_dir, gcb, chrs_test)\n",
    "    test_data = choose_features(test_data, feat_regex, label_col)\n",
    "    test_data.drop(columns=label_col, inplace=True)\n",
    "    test_data = TabularDataset(test_data)\n",
    "    #test_data = test_data.sample(n=5, random_state=0)\n",
    "    print('Test data prepared.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35662dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_model:\n",
    "    predictor = TabularPredictor.load(model_path)\n",
    "    y_pred = predictor.predict(test_data) # No label\n",
    "    \n",
    "    csv_pred_path = model_path + '_chrtest_' + chrs_test_id + '_MLtbl_pred.csv'\n",
    "    print(csv_pred_path)\n",
    "    y_pred.to_csv(csv_pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ebcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = timer()\n",
    "print(end - start)  # Time in seconds, e.g. 5.38091952400282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTES\n",
    "\n",
    "#holdout_frac\n",
    "# Baggin/stack ensembling - if enabled, dont provide tuning_data\n",
    "#num_bag_folds=5 # how many times the k-fold bagging process is repeated to further reduce variance (increasing this may further boost accuracy but will substantially increase training times, inference latency, and memory/disk usage)\n",
    "#num_bag_sets=1, \n",
    "#num_stack_levels=1 \n",
    "#auto_stack=True # Autogluon will select bagging/stacking numbers\n",
    "# specifying presets='best_quality' in fit() simply sets auto_stack=True\n",
    "\n",
    "#num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "#search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "#hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#    'num_trials': num_trials,\n",
    "#    'scheduler' : 'local',\n",
    "#    'searcher': search_strategy,\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
