{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9dc2af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7fb4cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whorunsit = 'LiezelMac'  # 'LiezelMac' | 'LiezelCluster'\n",
    "\n",
    "if whorunsit == 'LiezelMac':\n",
    "    home_dir = '/Users/ltamon'\n",
    "elif whorunsit == 'LiezelCluster':\n",
    "    home_dir = '/project/sahakyanlab/ltamon'\n",
    "else:\n",
    "    print(\"The supplied <whorunsit> option is not created in the script.\")\n",
    "\n",
    "wk_dir = home_dir + '/SahakyanLab/GenomicContactDynamics/26_PredictingCp'\n",
    "csv_dir = wk_dir + '/z_ignore_git/out_makeTable'\n",
    "#csv_dir = wk_dir + '/out_makeTable'\n",
    "out_dir = wk_dir + '/out_autogluon_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a002086",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_train_data = True\n",
    "fit_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94bc5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcb = 'min2Mb'\n",
    "chrs = ['chr22']\n",
    "feat_regex = 'grp.compl.|grp.kmer3.|grp.kmer1.|grp.GC.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3769abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_subsample = True\n",
    "percs = np.repeat([0.001,0.001], [18,3])\n",
    "groups = list(range(1,22))\n",
    "sampling_id = '5percExceptgrthn18'\n",
    "seed_val = 234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e754b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'LABEL'\n",
    "metric = 'accuracy'\n",
    "problem_type = 'multiclass' # (options: ‘binary’, ‘multiclass’, ‘regression’, ‘quantile’)\n",
    "\n",
    "presets = 'good_quality'\n",
    "time_limit = 60 # seconds\n",
    "label_count_threshold = 2 # For multi-class classification problems, this is the minimum number of times a label must appear in dataset in order to be considered an output class.\n",
    "\n",
    "#holdout_frac\n",
    "# Baggin/stack ensembling - if enabled, dont provide tuning_data\n",
    "#num_bag_folds=5 # how many times the k-fold bagging process is repeated to further reduce variance (increasing this may further boost accuracy but will substantially increase training times, inference latency, and memory/disk usage)\n",
    "#num_bag_sets=1, \n",
    "#num_stack_levels=1 \n",
    "#auto_stack=True # Autogluon will select bagging/stacking numbers\n",
    "# specifying presets='best_quality' in fit() simply sets auto_stack=True\n",
    "\n",
    "#num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "#search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "#hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#    'num_trials': num_trials,\n",
    "#    'scheduler' : 'local',\n",
    "#    'searcher': search_strategy,\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "861bdd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No chr23 -> chrX.\n"
     ]
    }
   ],
   "source": [
    "chrs_id = ''.join(chrs)\n",
    "try:\n",
    "    chrs[chrs.index('chr23')] = 'chrX'\n",
    "except ValueError:\n",
    "        print(\"No chr23 -> chrX.\")\n",
    "        \n",
    "feat_regex_id = re.compile('[^a-zA-Z0-9]').sub('', feat_regex)\n",
    "#[chrs_id, feat_regex_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3e1aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_chrcsv(csv_dir, gcb, chrs):\n",
    "    \n",
    "    df = []\n",
    "    [df.append(pd.read_csv( csv_dir + '/' + gcb + '_' + chr + '_MLtbl.csv' )) for chr in chrs]\n",
    "    df = pd.concat(df)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def choose_features(df, feat_regex, label_col):\n",
    "    \n",
    "    final_regex = feat_regex + '|' + label_col\n",
    "    is_chosen = [ bool(re.search(pattern=final_regex, string=feat)) for feat in df.columns ] \n",
    "    is_todrop = [not bool for bool in is_chosen]\n",
    "    df.drop(columns=list(df.columns[is_todrop]), inplace=True)\n",
    "\n",
    "    return(df)\n",
    "    \n",
    "def switch_contact(df):\n",
    "    \n",
    "    features = np.array(df.columns)\n",
    "    is_icol = ['.i_' in feat for feat in features]\n",
    "    is_jcol = ['.j_' in feat for feat in features]\n",
    "    \n",
    "    features_switch = np.array(features)\n",
    "    features_switch[is_icol] = features[is_jcol]\n",
    "    features_switch[is_jcol] = features[is_icol]\n",
    "    \n",
    "    df_switch = df.set_axis(features_switch, axis=1, inplace=False)\n",
    "    df_switch = df_switch[features]\n",
    "    df = pd.concat([df, df_switch])\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def sampleGroupInSeries(dfSeries, perc, group, seed_val):\n",
    "    \n",
    "    row_ind_group = dfSeries.index\n",
    "    row_ind_group = row_ind_group[ dfSeries == group ]\n",
    "    \n",
    "    np.random.seed(seed_val)\n",
    "    samp_size = math.ceil( sum(dfSeries == group) * perc / 100 )\n",
    "    row_ind_group_sampled = list( np.random.choice(a = row_ind_group, size=samp_size) )\n",
    "    \n",
    "    return(row_ind_group_sampled)\n",
    "\n",
    "def sampleManyGroupsInSeries(dfSeries, percs, groups, seed_val):\n",
    "    \n",
    "    num_groups = len(groups)\n",
    "    seed_generated = np.random.randint(low=0, high=1000, size=num_groups, dtype=int)\n",
    "    \n",
    "    row_ind_manygroups_sampled = []\n",
    "    \n",
    "    for i in range(num_groups):\n",
    "        \n",
    "        perc = percs[i]\n",
    "        group = groups[i]\n",
    "        seed_i = seed_generated[i]\n",
    "        \n",
    "        row_ind_manygroups_sampled = row_ind_manygroups_sampled + sampleGroupInSeries(dfSeries, perc, group, seed_val=seed_i)\n",
    "        \n",
    "    return(row_ind_manygroups_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "241d4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_id = gcb + '_' + chrs_id + '_MLtbl_' + feat_regex_id + '_seed' + str(seed_val) + '_' + sampling_id \n",
    "csv_path = csv_dir + '/' + csv_id + '.csv'\n",
    "#[csv_id, csv_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63c279ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "5percExceptgrthn18: Subsampled training data.\n",
      "Training data saved as CSV..\n"
     ]
    }
   ],
   "source": [
    "if generate_train_data:\n",
    "    \n",
    "    print(\"Generating training data...\")\n",
    "    \n",
    "    train_data = concat_chrcsv(csv_dir, gcb, chrs)\n",
    "    \n",
    "    if do_subsample:\n",
    "        ind = sampleManyGroupsInSeries(train_data['LABEL'], percs, groups, seed_val=seed_val)\n",
    "        train_data = train_data.iloc[ind,:]\n",
    "        print(sampling_id  + \": Subsampled training data.\")\n",
    "    else:\n",
    "        print(\"No subsampling of training data.\")\n",
    "    \n",
    "    train_data = choose_features(train_data, feat_regex, label_col)\n",
    "    train_data = switch_contact(train_data)\n",
    "    \n",
    "    if do_subsample:\n",
    "        train_data.to_csv(csv_path)\n",
    "        print(\"Training data saved as CSV..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab46f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_model:\n",
    "    \n",
    "    if do_subsample:\n",
    "        train_data = TabularDataset(csv_path)\n",
    "        train_data.drop(columns=train_data.columns[0], axis=1, inplace=True)\n",
    "        print(\"Training data loaded from CSV.\")\n",
    "    else:\n",
    "        train_data = TabularDataset(train_data)\n",
    "        \n",
    "    model_id = gcb + '_' + chrs_id + '_' + feat_regex_id + '_' + presets + '_' + str(time_limit) + 'sec_' + problem_type\n",
    "    model_id = model_id + '_' + str(len(train_data)) + 'subsample'\n",
    "    model_path = out_dir + '/' + 'agModel_' + model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7adeaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_model:\n",
    "    predictor = TabularPredictor(label=label_col, eval_metric=metric, path=model_path, problem_type=problem_type, learner_kwargs={'label_count_threshold': label_count_threshold}).fit(train_data, ag_args_fit={'num_gpus': num_gpus}, presets=presets, time_limit=time_limit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
